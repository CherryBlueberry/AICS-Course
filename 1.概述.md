#### 1.1 简述强人工智能和弱人工智能的区别

人工智能大致分为两大类：强人工智能和弱人工智能。弱人工智能(weak artificial intelligence)是能够完成某种特定具体任务的人工智能，换个角度看，就是一种计算机科学非常平凡的应用。强人工智能(strong artificial intelligence)或通用人工智能，是具备与人类同等智慧，或超越人类的人工智能，能表现正常人类所具有的所有智能行为。*（摘录自课本 Page 1）*

#### 1.2 简述人工智能研究的三个学派

人工智能按研究学派主要分为三类，包括行为主义(Behaviorism)，符号主义(Symbolism)，连接主义(Connectionism)。*（摘录自课本 Page 2）*

行为主义的核心思想是基于控制论构建感知-动作型控制系统。*（摘录自课本 Page 2）*在C.Shannon和J.McCarthy征集出版的《自动机研究》中有很多控制论方面的研究工作，涉及有有限自动机，图灵机、合成自动机，希望基于控制论去构建一些感知动作的反应性的控制系统。从比较直观的角度来看，行为主义的方法可以模拟出类似于小脑这样的人工智能，通过反馈来实现机器人的行走、抓取、平衡，因此有很大的实用价值。但是，这类方法似乎并不是通向人工智能的终极道路。*（摘录自课本 Page 5）*

符号主义是基于符号逻辑的方法，用逻辑表示知识和求解问题。其基本思想是：用一种逻辑把各种知识都表示出来；当求解一个问题时，就将该问题转化成一个逻辑表达式，然后用已有知识的逻辑表达式的库进行推理来解决该问题。但从逻辑的角度，难以找到一种简洁的符号逻辑体系，能表述出世间所有的知识。*（摘录自课本 Page 5）*从常识的角度，研究者还没能把一个实用领域中的所有常识都用逻辑表达式记录下来。从求解器的角度来看，解决问题的关键环节是逻辑求解器，而各种谓词逻辑一般都是不可判定的，也就是理论上不存在一种机械方法，能在有限时间内判定任意一个谓词逻辑表达式是否成立。*（摘录自课本 Page 6）*

连接主义方法的基本出发点是借鉴大脑中神经元细胞连接的计算模型，用人工神经网络来拟合智能行为。*（摘录自课本 Page 6）*连接主义方法始于1943年，从最开始的M-P神经元模型，到感知器模型、反向传播训练方法、卷积神经网络、深度学习、深度学习和反向传播训练方法，连接主义逐渐成为整个人工智能领域的主流方向。但是我们必须清楚的认识到，深度学习不一定是通向强人工智能的终极道路。它更像是一个能帮助我们快速爬到二楼、三楼的梯子，但顺着梯子我们很难爬到月球上。深度学习已知的局限性包括：泛化能力有限、缺乏推理能力、缺乏可解释性、鲁棒性欠佳等。*（摘录自课本 Page 7 Page 8）*

#### 1.3 一个由两个输入的单个神经元构成的感知机能完成什么任务？

首先，感知器是只有输入和输出层的神经网络:

<img alt="sensor" src="http://leiblog.wang/static/image/2020/12/5XViLH.png" style="zoom:50%;" />

在1958年，由美国心理学家Frank Rosenblatt提出的感知器模型中，激活函数采用的一般是符号函数，及输出
$$
o = sgn(x_1w_1+x_2*w_2+b)
$$
进一步表示为：
$$
\begin{cases}1 & x_1w_1+x_2*w_2+b>=0\\-1 & x_1w_1+x_2*w_2+b<0\end{cases}
$$
对于分界$x_1w_1+x2*w2+b=0$,表示的是二维平面上的一条直线，**及该感知机能完成的任务是用一条直线可以完成的分类任务**，比如可以完成逻辑“与”与逻辑“或”的分类：

1. 逻辑“与”的真值表和二维样本：

   | $x_1$ | $x_2$ | $x_3$ |
   | ----- | ----- | ----- |
   | 0     | 0     | 0     |
   | 0     | 1     | 0     |
   | 1     | 0     | 0     |
   | 1     | 1     | 1     |

   <img src="http://leiblog.wang/static/image/2020/12/tKn5qy.png" alt="与逻辑" style="zoom:50%;" />

2. 逻辑“或”的真值表和二维样本:

   | $x_1$ | $x_2$ | $x_3$ |
   | ----- | ----- | ----- |
   | 0     | 0     | 0     |
   | 0     | 1     | 1     |
   | 1     | 0     | 1     |
   | 1     | 1     | 1     |

   <img src="http://leiblog.wang/static/image/2020/12/3G80EB.png" alt="逻辑或" style="zoom:50%;" />

但是对于非线性问题，如异或问题，单层感知机就没办法实现了：

| $x_1$ | $x_2$ | $x_3$ |
| ----- | ----- | ----- |
| 0     | 0     | 0     |
| 0     | 1     | 1     |
| 1     | 0     | 1     |
| 1     | 1     | 0     |

<img src="http://leiblog.wang/static/image/2020/12/FUhIBE.png" alt="逻辑异或" style="zoom:50%;" />

> 多层感知机能够实现这一点，[这篇博客](https://blog.csdn.net/york1996/article/details/98846398)指出了这样一个观点:**Kolmogorov理论指出： 双隐层感知器就足以解决任何复杂的分类问题.**我仍然没有找到相关的证明，就和8bit就足够表示Feature Map一样迷惑。

