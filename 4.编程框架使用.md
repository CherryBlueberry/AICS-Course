### 4.1 请创建一个常量，在屏幕上输出"Hello, Tensorflow!"

Code:https://github.com/LeiWang1999/AICS-Course/blob/master/Code/4.1.hello.tensorflow.py

### 4.2 请实现两个数的加法，即计算A+B并输出，其中A是常量，B是占位符，数据类型自定。

Code:https://github.com/LeiWang1999/AICS-Course/blob/master/Code/4.2.addition.tensorflow.py

### 4.3 请实现一个矩阵乘法，数据类型和规模自定，并分别使用CPU和GPU执行。

Code:https://github.com/LeiWang1999/AICS-Course/blob/master/Code/4.3.multipy.tensorflow.py

附一下Docker环境的运行日志、加速大约八倍的加速效果：

```zsh
root@47f04df2e18b:/home/wanglei/AICS-Course/Code# python 4.3.multipy.tensorflow.py
1.15.3
[[ 3.4974059e-01 -1.2787011e-02  4.8799199e-01 ... -1.0545679e+00
  -9.0568960e-01 -1.2572201e+00]
 [-1.7671938e-01  2.8923857e-01 -7.4372232e-01 ...  1.7646760e+00
  -2.4357378e-01  9.6188837e-01]
 [-6.1920321e-01  2.6514995e-01 -2.2459249e+00 ... -5.0644886e-01
   8.4487319e-01  6.1570072e-01]
 ...
 [ 7.8543735e-01  2.7075319e-02  8.8574268e-02 ... -3.3353004e-01
  -2.3026823e-01  4.7881800e-01]
 [ 2.2726495e-02 -6.3107687e-01  2.6368400e-01 ... -2.1664791e+00
   8.1627607e-01  1.2454809e+00]
 [-1.9357489e-04  4.3001678e-02  1.4636961e+00 ... -2.1033468e+00
  -7.7237463e-01  1.9217274e+00]]
cpu process time 8.869284629821777 s
[[ 0.16940328  0.15450823 -0.15206526 ... -0.44589564 -0.4021014
  -0.19872668]
 [-0.12264346  0.11831289 -1.0659776  ... -0.07247161  0.00432087
  -0.02594075]
 [ 0.5666577  -0.37881672 -0.43297958 ... -0.11305187  0.00585366
  -0.22518606]
 ...
 [ 0.0912763   0.5537693  -0.06586529 ...  0.23703541  1.1658355
  -1.7276579 ]
 [-0.13596113  0.30294028  0.21194638 ... -0.44535032  0.52561086
  -2.244653  ]
 [ 0.90838486  0.616427    0.9101512  ...  0.11364561  0.845219
  -0.5584945 ]]
gpu process time 1.2381184101104736 s
```

### 4.4 请重构本章中的build_vggnet()、read_wb()、basic_calc()函数，使得在构建网络过程中只需要打开一次权重文件。

没有提供vgg_model.npy文件(

仅需要打开一次权重文件，那么就在build_vggnet之前把权重文件读入成为params dict、之后就直接对params dict进行操作就好了。

### 4.5 请调研了解OpenCV、Skimage和PIL等图像处理库的层次接口。使用这些库读入图片数据，以默认参数读入常规彩色图片后，存储数据时在Channel纬度分别是RGB还是BGR的顺序？这在数据预处理时需要注意什么？

Code:https://github.com/LeiWang1999/AICS-Course/tree/master/Code/4.5.imagemodule.python

在默认参数的情况下，对于OpenCV，读入彩色图像时候是BGR顺序、而对于Skimage和PIL是RGB接口。

并且在利用这些接口进行数据预处理时，不仅要注意RGB通道的顺序差异，还需要注意的有：

1. 数据读入和存储的类型，例如使用PIL框架进行图像存储，仅能存储uint8类型的图像，而cv可以存储任意类型，在进行深度学习推理的时候，网络的输入有时候是归一化到0～1之间的数据，也可能是uint8的数据，如果不同则推理的结果会有较大差异。
2. 还需要注意通道差异，例如读入的顺序是h,w,c,但对于一些深度学习框架、读入图像的顺序是c,h,w，如果输入的数据格式不同，会影响推理的结果。

### 4.6 请调研了解常用的图像数据预处理和数据增强的方法。实现一个函数，从ImageNet2012_val数据集中选择一张图片文件并读入数据，调整为(256，256，3)大小的图片，然后剧中裁剪为(224，224，3)大小的图片；再实现一个函数，读入数据后居中裁剪为(0.875 \* width, 0.875 \* height, 3)大小的图片，再调整为（224，224，3）大小的图片。

#### 常用的数据预处理方法：

- 进行图像的resize，因为神经网络的输入图像大小固定，所以需要resize。
- 每个图像通道减去均值mean，这一步的主要目的是消除图像的共性，突出每个图像的个性，也有的说法是将数据的分布调整到0中间、这样使用梯度下降反向传播算法的时候梯度的曲线就不会那么陡峭。

例如这是一张野兔的原图片。

<img src="http://leiblog.wang/static/image/2021/1/hare.jpg" style="zoom:50%;" />

进行ImageNet网络上的数据预处理之后，生成的图像如下图所示：

![](http://leiblog.wang/static/image/2021/1/331_hare.jpg)

#### 常见的数据增强方法

> 引用自：https://cloud.tencent.com/developer/news/314001

深度学习算法需要大量的训练数据，而有时我们收集不到太多的数据源，那么为了扩大数据集，可以采用数据增强手段来增加样本，常用的方法有：

- 随机裁剪
- 翻转或者镜像
- 旋转
- 调节亮度或者对比度
- 调节色度
- 调节图像的饱和度
- 将图像进行高斯模糊、锐化、添加噪声以及转换成灰度图像

要求编写的程序代码：https://github.com/LeiWang1999/AICS-Course/tree/master/Code/4.6.preprocess.python

### 4.7 请调研TFRecord格式，尝试将图像数据集（例如ImageNet2012_val数据集）制作成该格式的文件，并从该类型文件读入数据。

正常情况下我们训练文件夹经常会生成 train, test 或者val文件夹，这些文件夹内部往往会存着成千上万的图片或文本等文件，这些文件被散列存着，这样不仅占用磁盘空间，并且再被一个个读取的时候会非常慢，繁琐。占用大量内存空间（有的大型数据不足以一次性加载）。此时我们TFRecord格式的文件存储形式会很合理的帮我们存储数据。TFRecord内部使用了“Protocol Buffer”二进制数据编码方案，它只占用一个内存块，只需要一次性加载一个二进制文件的方式即可，简单，快速，尤其对大型训练数据很友好。而且当我们的训练数据量比较大的时候，可以将数据分成多个TFRecord文件，来提高处理效率。(转载自：https://www.jianshu.com/p/b480e5fcb638)

### 4.8 在神经网络训练过程中有时需要使用动态学习率。已知初始化学习率为0.1。每进行10000次迭代，学习率变为之前的0.9倍，使用梯度下降优化器和其他API实现该需求。

### 4.9 请计算VGG19网络在单batch且大小为(224，224，3)的输入情况下，经过每一个池化层后的张量形状大小。调研了解TensorBoard的使用方法，并使用TensorBoard将VGG19网络可视化，以查看网络信息并验证前面的计算。

### 4.10 请调研并参考相关资料，使用TensorFlow实现线性回归，k近邻等算法，在MNIST数据集上实现数字识别功能。



### 4.11 使用TensorFlow实现一个LeNet-5结构的神经网络，在MNIST数据集上实现数字识别。

### 4.12 请自行设计一个用于ImageNet数据图像分类的卷积神经网络，并调试精度使其达到85%（Top5精度）。